{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are two concepts used in probability theory and statistics to describe the probability distribution of a random variable.\n",
    "\n",
    "**1. Probability Mass Function (PMF):**\n",
    "- The Probability Mass Function (PMF) is used for discrete random variables.\n",
    "- It gives the probability of each possible outcome of a discrete random variable.\n",
    "- The PMF assigns a probability to each value of the random variable, allowing us to calculate the exact probability of observing a specific value.\n",
    "- The PMF is typically represented by a function that maps each possible value of the random variable to its corresponding probability.\n",
    "\n",
    "**Example:**\n",
    "Consider a fair six-sided die. The PMF of this die assigns a probability of 1/6 to each possible outcome (values 1, 2, 3, 4, 5, and 6) and assigns a probability of 0 to any other value outside this range. The PMF can be represented as:\n",
    "\n",
    "| Value | Probability |\n",
    "|-------|-------------|\n",
    "|   1   |   1/6       |\n",
    "|   2   |   1/6       |\n",
    "|   3   |   1/6       |\n",
    "|   4   |   1/6       |\n",
    "|   5   |   1/6       |\n",
    "|   6   |   1/6       |\n",
    "\n",
    "**2. Probability Density Function (PDF):**\n",
    "- The Probability Density Function (PDF) is used for continuous random variables.\n",
    "- It represents the density of the probability distribution over the range of possible values.\n",
    "- Unlike the PMF, the PDF does not give the exact probability of observing a specific value. Instead, it provides the relative likelihood of observing a value within a range.\n",
    "- The area under the PDF curve over a specific range represents the probability of observing a value within that range.\n",
    "\n",
    "**Example:**\n",
    "The PDF of a standard normal distribution (mean = 0, standard deviation = 1) is a bell-shaped curve. It describes the likelihood of observing different values of a continuous random variable. However, the PDF does not give the probability of a specific value. Instead, it provides the relative likelihood of observing values within different intervals along the x-axis.\n",
    "\n",
    "![Normal Distribution PDF](https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/330px-Normal_Distribution_PDF.svg.png)\n",
    "\n",
    "In summary, the PMF is used for discrete random variables and gives the probability of each possible outcome, while the PDF is used for continuous random variables and represents the density of the probability distribution over a range of values.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the cumulative Density Function(CDF) gives us the information about the probability that a random variable takes on a value less than or equal to given value .\n",
    "### the CDf is define as the integral or sum of the probability density function (PDF) or probability masss function (PMF) of a random varible up to certain value , it provides a way to understand the overall distribution of probabilities across diffrent values of the random variable  \n",
    "\n",
    "## Example\n",
    "\n",
    "- Consider a continuous random variable X following a standard normal distribution with a mean of 0 and a standard deviation of 1. The CDF of this distribution provides the probability that X takes on a value less than or equal to a given value.\n",
    "\n",
    "- For example, if we want to find the probability that X is less than or equal to 1, we can use the CDF. Using the standard normal distribution table or a statistical software, we find that the probability is approximately 0.8413. This means that around 84.13% of the data falls below 1 in a standard normal distribution.\n",
    "\n",
    "- In summary, the Cumulative Density Function (CDF) is a function that gives the probability that a random variable takes on a value less than or equal to a given value. It is used for probability calculation, percentile calculation, and distribution comparison, providing valuable insights into the probability distribution of a random variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Q3: What are some examples of situations where the normal distribution might be used as a model?  Explain how the parameters of the normal distribution relate to the shape of the distribution.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The normal distribution, also known as the Gaussian distribution or bell curve, is widely used as a model in various fields due to its versatile properties and applicability to many real-world situations. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "- Heights and Weights: The heights and weights of a large population tend to follow a normal distribution. This makes the normal distribution useful for modeling and understanding anthropometric measurements.\n",
    "\n",
    "- Test Scores: In educational settings, test scores often exhibit a normal distribution. This allows educators and researchers to analyze and compare performance using statistical techniques based on the normal distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Central Limit Theorem: The normal distribution plays a key role in the Central Limit Theorem (CLT). According to the CLT, the sum or average of a large number of independent and identically distributed random variables tends to follow a normal distribution, regardless of the underlying distribution of the individual variables. This theorem enables us to make probabilistic inferences and estimate parameters in various fields, even when the original data may not be normally distributed.\n",
    "\n",
    "#### Statistical Inference: Many statistical methods and tests are based on the assumption of normality. When the data follows a normal distribution, statistical inference becomes more reliable and valid. Techniques such as hypothesis testing, confidence intervals, and regression analysis often assume normality, allowing for better interpretation and analysis of results.\n",
    "\n",
    "#### Parameter Estimation: In several practical applications, estimating parameters such as means and variances is crucial. The normal distribution provides a solid framework for parameter estimation due to its mathematical properties. Maximum Likelihood Estimation (MLE) and other estimation methods are often employed with the assumption of normality.\n",
    "\n",
    "#### Predictive Modeling: Normal distribution is frequently utilized in predictive modeling and simulations. It serves as a foundation for generating random variables in simulations, which can be used to forecast and analyze outcomes in various scenarios. Many simulation models, such as Monte Carlo simulations, rely on the normal distribution as a basis for generating random inputs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes, typically referred to as success and failure. It is named after Jacob Bernoulli, a Swiss mathematician. The Bernoulli distribution is characterized by a single parameter, often denoted as p, which represents the probability of success in a single trial.\n",
    "\n",
    "#### Example: A common example of the Bernoulli distribution is modeling the outcome of a coin toss. Suppose we define success as obtaining a \"heads\" outcome and failure as obtaining a \"tails\" outcome. In this case, the probability of success (getting heads) is p, while the probability of failure (getting tails) is 1-p. The Bernoulli distribution captures the probability of obtaining heads (success) or tails (failure) in a single coin toss.\n",
    "\n",
    "**Bernoulli Distribution:**\n",
    "\n",
    "- Models a single trial or experiment with two possible outcomes (success and failure).\n",
    "- Characterized by a single parameter p, representing the probability of success.\n",
    "- The random variable in the Bernoulli distribution takes values of 1 (success) or 0 (failure).\n",
    "\n",
    " **Binomial Distribution:**\n",
    "\n",
    "- Models the number of successes in a fixed number of independent Bernoulli trials.\n",
    "- Characterized by two parameters: the number of trials (n) and the probability of success in each trial (p).\n",
    "- The random variable in the Binomial distribution represents the count of successes and can take values from 0 to n."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To calculate the probability that a randomly selected observation from a normally distributed dataset, with a mean of 50 and a standard deviation of 10, will be greater than 60, we can use the Z-score and the standard normal distribution table.\n",
    "\n",
    "#### The Z-score represents the number of standard deviations an observation is away from the mean. We can calculate the Z-score using the formula:\n",
    "\n",
    "**Z = (X - μ) / σ**\n",
    "\n",
    "#### where:\n",
    "\n",
    "- X is the value we want to find the probability for (60 in this case),\n",
    "- μ is the mean of the dataset (50), and\n",
    "- σ is the standard deviation of the dataset (10).\n",
    "- Let's calculate the Z-score:\n",
    "\n",
    "- Z = (60 - 50) / 10 = 1\n",
    "\n",
    "#### Now, we need to find the area to the right of the Z-score of 1 in the standard normal distribution table or using a statistical software. The area to the right represents the probability of a randomly selected observation being greater than 60.\n",
    "\n",
    "#### Using the standard normal distribution table, we can find that the area to the left of Z = 1 is approximately 0.8413. Therefore, the area to the right (probability of the observation being greater than 60) is:\n",
    "\n",
    "* Probability = 1 - 0.8413 = 0.1587\n",
    "\n",
    "#### So, the probability that a randomly selected observation from the given normally distributed dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Q7: Explain uniform Distribution with an example.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The uniform distribution represents a situation where all values within a specified range have an equal probability of occurring. It is often used in scenarios where fairness, equal likelihood, or randomness is desired.\n",
    "\n",
    "```scss \n",
    "f(x) = 1 / (b - a),  for a ≤ x ≤ b\n",
    "f(x) = 0,            otherwise\n",
    "\n",
    "In this example, the PDF of the uniform distribution for rolling a fair six-sided die would be:\n",
    " \n",
    "f(x) = 1/6,  for 1 ≤ x ≤ 6\n",
    "f(x) = 0,    otherwise\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q8: What is the z score? State the importance of the z score.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The z-score is a statistical measurement that tells us how far a data point is from the mean of a dataset in terms of standard deviations. It standardizes data, allowing for meaningful comparisons. The z-score is important because it helps us understand the relative position of data points, identify outliers, analyze data distributions, and perform hypothesis testing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The central limit theorem states that states that when independent random variables are summed or averaged, the distribution of their sum or average will tend to approximate a normal distribution, regardless of the shape of the original distribution.\n",
    "* in simple terms central limit theorm tells us that if we have large enough large sample size  the distribution or sum of will be approximataly normal ,even if the individual data points do not follow a normal distribution\n",
    "* the significance of the central limit theorem is that it allows us to make relieble refrences about population based on sample data. it is the reason why the normal distribution is so commonly used on stastical analysis . it enables us to use powerful statistical techinques to make accurate predictions even when we dont know the shape of the population distribution "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Q10: State the assumptions of the Central Limit Theorem.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Central Limit Theorem (CLT) relies on a few key assumptions in order to hold true. These assumptions include:\n",
    "\n",
    "1. Independent and Identically Distributed (IID) Random Variables: The random variables being averaged or summed should be independent of each other and have the same underlying distribution. This assumption ensures that the behavior of one variable does not affect the behavior of others and allows for the aggregation of their values.\n",
    "\n",
    "2. Finite Variance: The random variables should have a finite variance. Variance measures the spread of the data points around their mean. If the variance is infinite or doesn't exist, the CLT may not apply.\n",
    "\n",
    "3. Sample Size: The sample size should be sufficiently large. While there is no fixed threshold, a general rule of thumb is that the CLT starts to hold well when the sample size is greater than 30. However, for distributions that are highly skewed or have heavy tails, a larger sample size may be needed for the CLT to apply.\n",
    "\n",
    "#### It's important to note that violating these assumptions doesn't necessarily mean that the CLT will fail completely, but the approximation to a normal distribution may be less accurate or other techniques might be more appropriate.\n",
    "\n",
    "#### These assumptions are crucial in the context of the Central Limit Theorem as they provide the foundation for the theorem's applicability and the reliability of using the normal distribution as an approximation for the distribution of sample means or sums."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
